---
title: "basics"
author:
- name: Oliver M. Crook
- name: Broncio Aguilar-Sanjuan
date: "09/02/2022"
package: hdxstats
output:
  BiocStyle::html_document:
    toc_float: yes
abstract: "This vignette describes some of the basic objects and functions of `hdxstats`, an R package to analyse a mass-spectrometry based  hydrogen deuterium exchange (HDX) experiment, with focus on empirical Bayes functional models and visualisations. \n"
vignette: |
  %\VignetteIndexEntry{Analysing differential hydrogen deuterium exchange mass spectrometry data}
  %\VignetteEngine{knitr::rmarkdown}
  %%\VignetteKeywords{Mass Spectrometry, MS, MSMS, Proteomics, Metabolomics, Infrastructure, Quantitative} %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r env, message = FALSE, warning = FALSE, echo = FALSE}
library("hdxstats")
library("dplyr")
library("ggplot2")
library("RColorBrewer")
library("tidyr")
library("pheatmap")
library("scales")
library("viridis")
library("patchwork")
library("Biostrings")

```

# A well-defined HDX-MS experiment

This vignette describes how to analyse time-resolved differential HDX-MS
experiments. The key elements are at least two conditions i.e. apo + antibody,
apo + small molecule or protein closed + protien open, etc. The experiment can
be replicated, though if there are sufficient time points analysed (>=3) then
occasionally signficant results can be obtained. The data provided should be
centroid-centric data. This package does not yet support analysis straight
from raw spectra. Typically this will be provided as a .csv from tools such as
dynamiX or HDExaminer.

# Main elements of the package

The package relies of Bioconductor infrastructure so that it integrates with
other data types and can benefit from advantages in other fields of mass-spectrometry.
There are package specific object, classes and methods but importantly there is
reuse of classes found in quantitative proteomics data, mainly the `QFeatures`
object which extends the `SummarisedExperiment` class for mass spectrometry data.
The focus of this package is on testing and visualisation of the testing results.

# Data

We will begin with a structural variant experiment in which MHP and a structural
variant were mixed in different proportions. HDX-MS was performed on these samples
and we expect to see reproducible but subtle differences. We first load the data
from the package and it is .csv format.

```{r,}
csv_filename <- "MBP.csv"
csv_filepath <- system.file("extdata", csv_filename, package = "hdxstats")
```

We can now read in the .csv file and have a quick look at the .csv.
```{r,}
data <- read.csv(csv_filepath)
head(data) # have a look
```

```{r,}
length(unique(data$pep_sequence)) # peptide sequences
```

Let us have a quick visualisation of some the data so that we can see some of
the features

```{r,}
condition1 <- data$pep_sequence == unique(data$pep_sequence[1])
condition2 <- data$pep_charge == 2
data_filtered <- filter(data, condition1, condition2)

selection <- c(7,5,1,2,3,4,6)
colors <- factor(data_filtered$hx_sample, unique(data$hx_sample)[selection])
colormap <- "Set2"
point_size <- 2

# make a pretty plot
data_filtered %>%
    ggplot(aes(x = hx_time, y = d, group = factor(replicate_cnt), color = colors)) + 
    # further customise plot
    theme_classic() +
    geom_point(size = point_size) + 
    scale_color_manual(values = brewer.pal(n = 7, name = colormap)) + 
    labs(color = "experiment", 
         x = "Deuterium Exposure", 
         y = "Deuterium incoperation"
         )

```


We can see that the units of the time dimension are in seconds and that
Deuterium incorporation has been normalized into Daltons (`Da`).

# Parsing to an object of class QFeatures

Working from a .csv is likely to cause issues downstream. Indeed, we run
the risk of accidentally changing the data or corrupting the file in some way.
Secondly, all `.csv` file will be formatted slightly different and so making extensible
tools for these files will be inefficient. Furthermore, working with a generic
class used in other mass-spectrometry fields can speed up analysis and adoption
of new methods. We will work with the class `QFeatures` from the `QFeatures` class
as it is a powerful and scalable way to store quantitative mass-spectrometry data.

Firstly, the data is stored in long format rather than wide format. We first 
switch the data to wide format.

```{r,}
columns_names <- c("hx_time", "replicate_cnt", "hx_sample") # to merge into new column names
columns_fixed <- c("pep_sequence", "pep_charge")

# transform data
data_wide <- pivot_wider(data.frame(data),
                        values_from = d,
                        names_from = columns_names,
                        id_cols = columns_fixed
                        )

# check how the data looks like now
head(data_wide)
```


Next, we notice that there are many columns with `NA` values. The follow code chunk removes
these columns.

```{r,}
data_wide <- data_wide[, colSums(is.na(data_wide)) != nrow(data_wide)]

# check how the data looks like now
head(data_wide)
```

We can see that the number of columns has changed from 198 to 102 only. 

Now, we note that the column names are not very informative. We are going to format these
in a very specific way so that later functions can automatically infer the design
from the column names. We impose the following format `X(time) rep(replicate) cond(condition)`

```{r,}
columns_to_remove <- c(1,2) # subtract names from first two columns
old_columns_names <- colnames(data_wide)[-columns_to_remove]  

# add X and rep markers to new column names
new_object.colnames <- paste0("X", old_columns_names)
new_object.colnames <- gsub("0_", "0rep", new_object.colnames)
new_object.colnames <- gsub("_", "cond", new_object.colnames)
# remove annoying % signs
new_object.colnames <- gsub("%", "", new_object.colnames)
# remove space (NULL could get confusing later and WT is clear)
new_object.colnames <- gsub(" .*", "", new_object.colnames)

# Compare old and new column names
old_columns_names
new_object.colnames
```

We will now parse the data into an object of class `QFeatures`, we have provided
a function to assist with this in the package. If you want to do this yourself
use the `readQFeatures` function from the `QFeatures` package.

```{r,}
# column range corresponding to numeric data
initial_column <- 3
last_column <- 102

# hdxstats method
data_qDF <- parseDeutData(object = DataFrame(data_wide),
                          design = new_object.colnames,
                          quantcol = initial_column:last_column
                          )

```

We save this object for future use in the vignettes ahead
```{r,}
saveRDS(data_qDF, file='data/MBPqDF.rsd')
```

# Heatmap visualisations of HDX data

To help us get used to the `QFeatures` we show how to generate a `heatmap`
of these data from this object:

```{r, fig.height = 16, fig.width = 20, fig.align = "center"}
data_qDF_transposed <- t(assay(data_qDF))

# parameters to customise heatmap plot
colors_discrete <- brewer.pal(n = 9, name = "BuPu") # colours from discrete colormap (BuPu)
legend_labels <- c("0", "2", "4", "6", "8","10", "12", "Incorporation")
legend_breaks <- c(0, 2, 4, 6, 8, 10, 12, max(assay(data_qDF)))
title <- "Structural Variant Deuterium Incorporation"

pheatmap(data_qDF_transposed,
         cluster_rows = FALSE, 
         cluster_cols = FALSE,
         color = colors_discrete,
         main = title, 
         fontsize = 14,
         legend_breaks = legend_breaks,
         legend_labels = legend_labels
         )
```

If you prefer to have the start-to-end residue numbers in the `heatmap` instead
you can change the plot as follows

```{r, fig.height = 16, fig.width = 20, fig.align = "center"}
data_qDF_transposed <- t(assay(data_qDF))

# parameters to customise heatmap plot
colors_discrete <- brewer.pal(n = 9, name = "BuPu") # colours from discrete colormap (BuPu)
legend_labels <- c("0", "2", "4", "6", "8","10", "12", "Incorporation")
legend_breaks <- c(0, 2, 4, 6, 8, 10, 12, max(assay(data_qDF)))
title <- "Structural Variant Deuterium Incorporation"

# take start-to-end residue numbers
regions <- unique(data[,c("pep_start", "pep_end")])
column_labels_new <- paste0("[", regions[,1], ",", regions[,2], "]")

pheatmap(data_qDF_transposed,
         cluster_rows = FALSE, 
         cluster_cols = FALSE,
         color = colors_discrete,
         main = title, 
         fontsize = 14,
         legend_breaks = legend_breaks,
         legend_labels = legend_labels,
         labels_col = column_labels_new
         )
```

It maybe useful to normalise HDX-MS data for either interpretation or 
visualization purposes. We can normalize by the percentage (`pc`) of exchangeable amides 
or by using back-exchange correction values (`bc`). We first use percentage
incorporation as normalisation and visualise as a heatmap.

```{r, fig.height = 16, fig.width = 20, fig.align = "center"}
# normalised data with hdxstats method
data_qDF_normalised <- normalisehdx(data_qDF,
                                    sequence = unique(data$pep_sequence),
                                    method = "pc")

data_qDF_transposed <- t(assay(data_qDF_normalised))

# parameters to customise heatmap plot
colors_discrete <- brewer.pal(n = 9, name = "BuPu") # colours from discrete colormap (BuPu)
legend_labels_new <- c("0", "0.2", "0.4", "0.6", "0.8","1", "Incorporation")
legend_breaks_new <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2)
title_new <- "Structural Variant Deuterium Incorporation: Normalised by Percentage Incorporation"

# take start-to-end residue numbers
regions <- unique(data[,c("pep_start", "pep_end")])
column_labels_new <- paste0("[", regions[,1], ",", regions[,2], "]")

pheatmap(data_qDF_transposed,
         cluster_rows = FALSE, 
         cluster_cols = FALSE,
         color = colors_discrete,
         main = title_new, 
         fontsize = 14,
         legend_breaks = legend_breaks_new,
         legend_labels = legend_labels_new,
         labels_col = column_labels_new
         )
```

Now, we demonstrate a back-exchange correction (`bc`) calculation. The 
back-exchange value are fictitious by the code chunk below demonstrates how
to set this up.

```{r, fig.height = 16, fig.width = 20, fig.align = "center"}
# made-up correction factor using hdxstats method: exchangeableAmides
correction <- (exchangeableAmides(unique(data$pep_sequence)) + 1) * 0.9

data_qDF_normalised <- normalisehdx(data_qDF,
                                    sequence = unique(data$pep_sequence),
                                    method = "bc", 
                                    correction = correction
                                    )

data_qDF_normalised <- t(assay(data_qDF_normalised))

# parameters to customise heatmap plot
colors_discrete <- brewer.pal(n = 9, name = "BuPu") # colours from discrete colormap (BuPu)
legend_labels_new <- c("0", "0.2", "0.4", "0.6", "0.8","1", "Incorporation")
legend_breaks_new <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2)
title_new <- "Structural Variant Deuterium Incorporation: Normalised by Back-exchange Correction"

# take start-to-end residue numbers
regions <- unique(data[,c("pep_start", "pep_end")])
column_labels_new <- paste0("[", regions[,1], ",", regions[,2], "]")

pheatmap(data_qDF_transposed,
         cluster_rows = FALSE, 
         cluster_cols = FALSE,
         color = colors_discrete,
         main = title_new, 
         fontsize = 14,
         legend_breaks = legend_breaks_new,
         legend_labels = legend_labels_new,
         labels_col = column_labels_new
         )
```

# Functional data analysis of HDX-MS data

The `hdxstats` package uses an _empirical Bayes functional approach_ to analyse
the data. We illustrate this idea in steps so that we can get an idea of the approach.

First, we fit a parametric model to the data restricted to a single randomly chosen peptide.
We explore the `HdxStatModel` class objects and their attributes.

```{r,}
all_peptides <- rownames(data_qDF)[[1]] # get all peptides
selected_peptide <- all_peptides[37] # randomly picked

fitting_method <- differentialUptakeKinetics # model for fitting
starting_parameters <- list(a = NULL, b = 0.0001,  d = NULL, p = 1) # initial model parameter guesses

# HdxStatModel class object
result <- fitting_method(object = data_qDF[,1:100], #provide a QFeature object
                         feature = selected_peptide, # which peptide to do we fit
                         start = starting_parameters
                         ) 
```

Here, we see the `HdxStatModel` class, and that a Functional Model was applied
to the data and a total of 7 models were fitted, for each available experimental condition.

```{r,}
result
```

The `result` object provides several slots providing several pieces of informat at once.
For instance, the `nullmodel` and `alternative` slots provide the underlying fitted models. 
The `method` and `formula` slots provide vital information about what analysis was performed. 
The `vis` slot provides a `ggplot` object so that we can visualise the functional fits.

Let's play now with the visualisation slot!

```{r,}
result@vis
```

Since this is a `ggplot` object, we can customise it in the usual grammatical ways.

```{r,}
colors <- brewer.pal(n = 8, name = "Set2")

result@vis + scale_color_manual(values = colors)
```

A number of standard methods are available and can be applied to a `HdxStatModels` object,
these extend the usual `base` stats methods. These include

1. `anova`: An analysis of variance
2. `logLik`: The log-likelihood of all the fitted models
3. `residuals`: The residuals for the fitted models
4. `vcov`: The variance-covariance matrix between parameters of the models
5. `likRatio`: The likelihood ratio between null and alternative models
6. `wilk`: Applies wilk's theorem to obtain a p-value from the likelihood ratio
7. `coef`: The fitted model coefficients
8. `deviance`: The deviance of the fitted models
9. `summary`: The statistical summary of the models.

Let's tests these now.

```{r,}
anova(result)
logLik(result)
residuals(result)
vcov(result)
likRatio(result)
wilk(result)
coef(result)
deviance(result)
summary(result)
```
